{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to follow\n",
    "\n",
    "1. Get train test split\n",
    "1. Fit default model. Also fit using cross validation\n",
    "2. Evaluate the model\n",
    "3. Change parameters and hyperparameters\n",
    "4. Evaluate all models\n",
    "5. Compare all models\n",
    "6. Find out feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imoprt libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit,cross_validate, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import log_loss,classification_report,confusion_matrix, roc_curve, roc_auc_score,accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# over sampling for imbalanced classes\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE, ADASYN\n",
    "from imblearn.under_sampling import ClusterCentroids, RandomUnderSampler, NearMiss, EditedNearestNeighbours, RepeatedEditedNearestNeighbours,InstanceHardnessThreshold\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# calculate weights for imbablanced classes\n",
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.402093</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>-0.279443</td>\n",
       "      <td>-0.161867</td>\n",
       "      <td>-0.119331</td>\n",
       "      <td>-0.188045</td>\n",
       "      <td>-0.293664</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>-0.243606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246100</td>\n",
       "      <td>-0.420870</td>\n",
       "      <td>-0.249802</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>-0.176699</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.253508</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>-0.279443</td>\n",
       "      <td>-0.161867</td>\n",
       "      <td>-0.119331</td>\n",
       "      <td>-0.188045</td>\n",
       "      <td>0.149647</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>-0.243606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280099</td>\n",
       "      <td>-0.420870</td>\n",
       "      <td>-0.249802</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>-0.176699</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.253508</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>-0.279443</td>\n",
       "      <td>-0.161867</td>\n",
       "      <td>-0.119331</td>\n",
       "      <td>-0.188045</td>\n",
       "      <td>0.149647</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>-0.243606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280099</td>\n",
       "      <td>-0.420870</td>\n",
       "      <td>-0.249802</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>-0.176699</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.402093</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>0.079240</td>\n",
       "      <td>13.508710</td>\n",
       "      <td>4.524667</td>\n",
       "      <td>4.665884</td>\n",
       "      <td>-0.293664</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>0.679472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280099</td>\n",
       "      <td>-0.047949</td>\n",
       "      <td>1.019683</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>-0.176699</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.253508</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>-0.279443</td>\n",
       "      <td>-0.161867</td>\n",
       "      <td>-0.119331</td>\n",
       "      <td>-0.188045</td>\n",
       "      <td>-0.293664</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>-0.243606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246100</td>\n",
       "      <td>-0.420870</td>\n",
       "      <td>-0.249802</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>0.040798</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3          4         5         6  \\\n",
       "0  0.402093 -0.210106 -0.307165 -0.279443  -0.161867 -0.119331 -0.188045   \n",
       "1 -0.253508 -0.210106 -0.307165 -0.279443  -0.161867 -0.119331 -0.188045   \n",
       "2 -0.253508 -0.210106 -0.307165 -0.279443  -0.161867 -0.119331 -0.188045   \n",
       "3  0.402093 -0.210106 -0.307165  0.079240  13.508710  4.524667  4.665884   \n",
       "4 -0.253508 -0.210106 -0.307165 -0.279443  -0.161867 -0.119331 -0.188045   \n",
       "\n",
       "          7         8         9   ...          84        85        86  \\\n",
       "0 -0.293664 -0.291038 -0.243606   ...    0.246100 -0.420870 -0.249802   \n",
       "1  0.149647 -0.291038 -0.243606   ...   -0.280099 -0.420870 -0.249802   \n",
       "2  0.149647 -0.291038 -0.243606   ...   -0.280099 -0.420870 -0.249802   \n",
       "3 -0.293664 -0.291038  0.679472   ...   -0.280099 -0.047949  1.019683   \n",
       "4 -0.293664 -0.291038 -0.243606   ...    0.246100 -0.420870 -0.249802   \n",
       "\n",
       "         87        88        89        90        91        92  target  \n",
       "0 -0.413584 -0.299712 -0.176699 -0.129516 -0.386938 -0.104963       1  \n",
       "1 -0.413584 -0.299712 -0.176699 -0.129516 -0.386938 -0.104963       1  \n",
       "2 -0.413584 -0.299712 -0.176699 -0.129516 -0.386938 -0.104963       1  \n",
       "3 -0.413584 -0.299712 -0.176699 -0.129516 -0.386938 -0.104963       1  \n",
       "4 -0.413584 -0.299712  0.040798 -0.129516 -0.386938 -0.104963       1  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should I use normalized data for all models?\n",
    "# using pca components instead of normal features is a good idea? I don't think so.\n",
    "# for logistic regression it is better to use nomralized data\n",
    "\n",
    "df = pd.read_csv(\"../data/train_norm.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=1, random_state=42, test_size=0.1,\n",
      "            train_size=None)\n"
     ]
    }
   ],
   "source": [
    "# here the classes are imbalanced so we should use stratified split \n",
    "# the folds are made by preserving the percentage of samples for each class\n",
    "# note that the imbalance will still be their when we train the model using this split\n",
    "\n",
    "# since we have big amount of data our test set can be just 1% of all data\n",
    "sss = StratifiedShuffleSplit(n_splits=1,test_size=0.1, random_state=42)\n",
    "print(sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [57972 30244  9427 ..., 60232 28576 27516] TEST: [59081 21681 51999 ...,  1777   269 53901]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"target\",axis=1)\n",
    "y = df.target\n",
    "\n",
    "train_index = []\n",
    "test_index = []\n",
    "\n",
    "for tr, tes in sss.split(X,y):\n",
    "    print(\"TRAIN:\", tr, \"TEST:\", tes)\n",
    "    train_index = tr\n",
    "    test_index = tes\n",
    "\n",
    "X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of data sets\n",
      "X_train:  (55690, 93) y_train:  (55690,)\n",
      "X_train:  (6188, 93) y_test:  (6188,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes of data sets\")\n",
    "print(\"X_train: \", X_train.shape, \"y_train: \", y_train.shape)\n",
    "print(\"X_train: \", X_test.shape,\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(m):\n",
    "    print(\"Train score: \",m.score(X_train,y_train).round(5))\n",
    "    print(\"Test score: \",m.score(X_test,y_test).round(5))\n",
    "    print(\"Log loss train: \",log_loss(y_train, m.predict_proba(X_train)).round(5))\n",
    "    print(\"Log loss test: \",log_loss(y_test, m.predict_proba(X_test)).round(5))\n",
    "    print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, m.predict(X_test),labels=m.classes_))\n",
    "    print(\"\\nClassification Report: \\n\", classification_report(y_test, m.predict(X_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model_balance(m,y_train,y_test):\n",
    "    print(\"Train score: \",m.score(X_train,y_train).round(5))\n",
    "    print(\"Test score: \",m.score(X_test,y_test).round(5))\n",
    "    print(\"Log loss train: \",log_loss(y_train, m.predict_proba(X_train)).round(5))\n",
    "    print(\"Log loss test: \",log_loss(y_test, m.predict_proba(X_test)).round(5))\n",
    "    print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, m.predict(X_test),labels=m.classes_))\n",
    "    print(\"\\nClassification Report: \\n\", classification_report(y_test, m.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_imp(m):\n",
    "    coef_df = pd.DataFrame(m.coef_)\n",
    "    coef_df = np.absolute(np.round(coef_df,5))\n",
    "\n",
    "    imp_features = [0]*9\n",
    "    for row in np.arange(0,9,1):\n",
    "        # top coefficients for each class\n",
    "        imp_features[row] = sorted(enumerate(coef_df.iloc[row]), \\\n",
    "                                   key=lambda x:x[1],reverse=True)[0:5]\n",
    "\n",
    "    print(\"Most important features: \\n\",np.unique(np.transpose(imp_features)[0])+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.75716\n",
      "Test score:  0.75533\n",
      "Log loss train:  0.66281\n",
      "Log loss test:  0.67151\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  56   27    0    0    0   21    2   41   46]\n",
      " [   0 1438  138    5    8    6   10    5    2]\n",
      " [   0  565  217    3    0    1   10    3    1]\n",
      " [   0  168   29   45    4   19    4    0    0]\n",
      " [   0   15    2    0  257    0    0    0    0]\n",
      " [   3   34    1    3    0 1301   23   29   20]\n",
      " [   2   55   20    1    0   30  159   14    3]\n",
      " [  10   16    2    0    0   27   10  772    9]\n",
      " [   5   26    0    1    0   15    1   19  429]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.29      0.42       193\n",
      "          2       0.61      0.89      0.73      1612\n",
      "          3       0.53      0.27      0.36       800\n",
      "          4       0.78      0.17      0.28       269\n",
      "          5       0.96      0.94      0.95       274\n",
      "          6       0.92      0.92      0.92      1414\n",
      "          7       0.73      0.56      0.63       284\n",
      "          8       0.87      0.91      0.89       846\n",
      "          9       0.84      0.86      0.85       496\n",
      "\n",
      "avg / total       0.76      0.76      0.73      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important features: \n",
      " [  9.  11.  14.  15.  26.  27.  34.  39.  40.  42.  43.  45.  47.  58.  60.\n",
      "  69.  73.  75.  76.  78.  83.  84.  86.  90.]\n"
     ]
    }
   ],
   "source": [
    "feature_imp(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LogisticRegressionCV\n",
    "params = {\"cv\":5, \"random_state\":42}\n",
    "lrcv = LogisticRegressionCV(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.75726\n",
      "Test score:  0.75727\n",
      "Log loss train:  0.66178\n",
      "Log loss test:  0.6707\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  57   25    0    0    0   21    3   41   46]\n",
      " [   0 1442  137    4    6    6   10    5    2]\n",
      " [   0  561  221    3    0    1   10    3    1]\n",
      " [   0  168   30   44    4   19    4    0    0]\n",
      " [   0   13    2    0  259    0    0    0    0]\n",
      " [   3   35    1    3    1 1302   23   27   19]\n",
      " [   2   53   20    1    1   30  160   14    3]\n",
      " [  11   17    1    0    0   26    9  773    9]\n",
      " [   5   27    0    1    0   15    1   19  428]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.30      0.42       193\n",
      "          2       0.62      0.89      0.73      1612\n",
      "          3       0.54      0.28      0.36       800\n",
      "          4       0.79      0.16      0.27       269\n",
      "          5       0.96      0.95      0.95       274\n",
      "          6       0.92      0.92      0.92      1414\n",
      "          7       0.73      0.56      0.63       284\n",
      "          8       0.88      0.91      0.89       846\n",
      "          9       0.84      0.86      0.85       496\n",
      "\n",
      "avg / total       0.76      0.76      0.73      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(lrcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important features: \n",
      " [  9.  11.  14.  15.  26.  27.  36.  39.  40.  42.  43.  45.  47.  58.  59.\n",
      "  60.  68.  69.  73.  75.  76.  83.  84.  86.  90.]\n"
     ]
    }
   ],
   "source": [
    "feature_imp(lrcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "C_param_range = [100,300,1000]\n",
    "gcv = GridSearchCV(estimator=lr, cv=3,scoring=\"neg_log_loss\",param_grid={\"C\":C_param_range})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [100, 300, 1000]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='neg_log_loss',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_best = gcv.best_estimator_.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cv': 3, 'random_state': 32, 'Cs': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=100, class_weight=None, cv=3, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=32,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using LogisticRegressionCV\n",
    "params = {\"cv\":3,\"random_state\":32}\n",
    "params.update({\"Cs\":100})\n",
    "print(params)\n",
    "lrcv2 = LogisticRegressionCV()\n",
    "lrcv2.set_params(**params)\n",
    "#lrcv2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of LogisticRegressionCV(Cs=100, class_weight=None, cv=3, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv2.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.75734\n",
      "Test score:  0.7563\n",
      "Log loss train:  0.66156\n",
      "Log loss test:  0.67022\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  57   26    0    0    0   21    2   41   46]\n",
      " [   0 1442  137    4    6    6   10    5    2]\n",
      " [   0  565  219    1    0    1   10    3    1]\n",
      " [   0  172   29   41    4   19    4    0    0]\n",
      " [   0   13    2    0  259    0    0    0    0]\n",
      " [   3   35    1    3    1 1301   23   27   20]\n",
      " [   2   53   20    1    1   30  160   14    3]\n",
      " [  11   17    1    0    0   27    9  772    9]\n",
      " [   5   26    0    1    0   15    1   19  429]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.30      0.42       193\n",
      "          2       0.61      0.89      0.73      1612\n",
      "          3       0.54      0.27      0.36       800\n",
      "          4       0.80      0.15      0.26       269\n",
      "          5       0.96      0.95      0.95       274\n",
      "          6       0.92      0.92      0.92      1414\n",
      "          7       0.73      0.56      0.64       284\n",
      "          8       0.88      0.91      0.89       846\n",
      "          9       0.84      0.86      0.85       496\n",
      "\n",
      "avg / total       0.76      0.76      0.73      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(lrcv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=100, class_weight=None, cv=3, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,\n",
       "           refit=True, scoring='neg_log_loss', solver='lbfgs', tol=0.0001,\n",
       "           verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv3 = LogisticRegressionCV(cv=3, random_state=42,Cs=C_best,scoring=('neg_log_loss'))\n",
    "lrcv3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.75707\n",
      "Test score:  0.75533\n",
      "Log loss train:  0.66288\n",
      "Log loss test:  0.67171\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  57   27    0    0    0   21    2   40   46]\n",
      " [   0 1439  138    5    7    6   10    5    2]\n",
      " [   0  565  218    2    0    1   11    3    0]\n",
      " [   0  168   29   44    4   19    5    0    0]\n",
      " [   0   15    2    0  257    0    0    0    0]\n",
      " [   3   36    1    3    1 1302   22   26   20]\n",
      " [   2   55   21    1    0   31  157   14    3]\n",
      " [  11   17    1    0    0   28    9  771    9]\n",
      " [   5   26    0    1    0   15    1   19  429]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.30      0.42       193\n",
      "          2       0.61      0.89      0.73      1612\n",
      "          3       0.53      0.27      0.36       800\n",
      "          4       0.79      0.16      0.27       269\n",
      "          5       0.96      0.94      0.95       274\n",
      "          6       0.91      0.92      0.92      1414\n",
      "          7       0.72      0.55      0.63       284\n",
      "          8       0.88      0.91      0.89       846\n",
      "          9       0.84      0.86      0.85       496\n",
      "\n",
      "avg / total       0.76      0.76      0.73      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(lrcv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cross validation library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([ 15.76905894,  15.40101194,  14.45040584]),\n",
       " 'score_time': array([ 0.01995587,  0.0199542 ,  0.01813412]),\n",
       " 'test_score': array([-0.68030046, -0.67570131, -0.6716733 ]),\n",
       " 'train_score': array([-0.65810914, -0.66169568, -0.66303738])}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(estimator=lr,cv=3,X=X_train,y=y_train,scoring=('neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive random over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_os, y_os = rs.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((130590, 93), (130590,))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_os.shape, y_os.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X=X_os,y=y_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.71501\n",
      "Test score:  0.71025\n",
      "Log loss train:  0.78172\n",
      "Log loss test:  0.79707\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 140    2    2    2    2    3    7   14   21]\n",
      " [  23  909  329  291   17    3   32    3    5]\n",
      " [   2  205  371  175    2    1   41    0    3]\n",
      " [   0   38   28  181    5    7   10    0    0]\n",
      " [   1    3    2    0  268    0    0    0    0]\n",
      " [  58    7    4   22    2 1215   46   21   39]\n",
      " [  19    7   16   17    0    3  215    4    3]\n",
      " [  81    3    4    0    0   12   19  714   13]\n",
      " [  79    5    1    5    0   10    3   11  382]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.35      0.73      0.47       193\n",
      "          2       0.77      0.56      0.65      1612\n",
      "          3       0.49      0.46      0.48       800\n",
      "          4       0.26      0.67      0.38       269\n",
      "          5       0.91      0.98      0.94       274\n",
      "          6       0.97      0.86      0.91      1414\n",
      "          7       0.58      0.76      0.65       284\n",
      "          8       0.93      0.84      0.89       846\n",
      "          9       0.82      0.77      0.79       496\n",
      "\n",
      "avg / total       0.77      0.71      0.73      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important features: \n",
      " [ 11.  14.  15.  19.  26.  34.  39.  43.  45.  47.  58.  59.  60.  69.  73.\n",
      "  75.  76.  78.  83.  84.  86.  90.  91.  92.]\n"
     ]
    }
   ],
   "source": [
    "feature_imp(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above naive random over sampling did worse results then our original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE, ADASYN oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_os, y_os = smote.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((130590, 93), (130590,))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_os.shape, y_os.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X=X_os,y=y_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.71354\n",
      "Test score:  0.70814\n",
      "Log loss train:  0.76569\n",
      "Log loss test:  0.78492\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 137    3    1    2    1    3    8   17   21]\n",
      " [  27  866  350  304   13    4   40    3    5]\n",
      " [   2  185  382  184    2    1   42    0    2]\n",
      " [   0   37   29  181    5    7   10    0    0]\n",
      " [   1    3    2    0  268    0    0    0    0]\n",
      " [  55    7    3   21    2 1224   45   21   36]\n",
      " [  19    6   14   15    0    4  217    5    4]\n",
      " [  68    2    4    0    0   12   23  724   13]\n",
      " [  77    4    1    5    0   12    3   11  383]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.35      0.71      0.47       193\n",
      "          2       0.78      0.54      0.64      1612\n",
      "          3       0.49      0.48      0.48       800\n",
      "          4       0.25      0.67      0.37       269\n",
      "          5       0.92      0.98      0.95       274\n",
      "          6       0.97      0.87      0.91      1414\n",
      "          7       0.56      0.76      0.65       284\n",
      "          8       0.93      0.86      0.89       846\n",
      "          9       0.83      0.77      0.80       496\n",
      "\n",
      "avg / total       0.77      0.71      0.72      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adasyn = ADASYN(n_neighbors=5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_os, y_os = adasyn.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((131124, 93), (131124,))"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_os.shape, y_os.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X=X_os,y=y_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.69154\n",
      "Test score:  0.68714\n",
      "Log loss train:  0.81283\n",
      "Log loss test:  0.8348\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 122    2    1    1    2    2   12   18   33]\n",
      " [  25  778  334  327   70    1   53    9   15]\n",
      " [   2  159  351  200   20    1   55    8    4]\n",
      " [   0   24   27  187    9    6   13    0    3]\n",
      " [   0    1    2    0  271    0    0    0    0]\n",
      " [  44    3    1   11   11 1199   53   36   56]\n",
      " [  14    4   10   16    3    4  223    6    4]\n",
      " [  54    4    2    0    3    8   24  732   19]\n",
      " [  69    1    2    3    7    7    6   12  389]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.37      0.63      0.47       193\n",
      "          2       0.80      0.48      0.60      1612\n",
      "          3       0.48      0.44      0.46       800\n",
      "          4       0.25      0.70      0.37       269\n",
      "          5       0.68      0.99      0.81       274\n",
      "          6       0.98      0.85      0.91      1414\n",
      "          7       0.51      0.79      0.62       284\n",
      "          8       0.89      0.87      0.88       846\n",
      "          9       0.74      0.78      0.76       496\n",
      "\n",
      "avg / total       0.75      0.69      0.70      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype generation under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc = ClusterCentroids(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_os, y_os = cc.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15624, 93), (15624,))"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_os.shape, y_os.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X=X_os,y=y_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.59224\n",
      "Test score:  0.58759\n",
      "Log loss train:  0.97031\n",
      "Log loss test:  0.99595\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 149    2    2    3    2    3    6    9   17]\n",
      " [  72  453  280  744   36    1   20    2    4]\n",
      " [  16   99  312  337    7    1   27    0    1]\n",
      " [   6   14   17  218    6    3    5    0    0]\n",
      " [   3    1    0    1  269    0    0    0    0]\n",
      " [ 136    4    5   50    4 1131   37   15   32]\n",
      " [  34    3   14   33    2    1  191    3    3]\n",
      " [ 187    5    6    6    4   11   21  592   14]\n",
      " [ 155    1    0    7    0    5    1    6  321]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.20      0.77      0.31       193\n",
      "          2       0.78      0.28      0.41      1612\n",
      "          3       0.49      0.39      0.43       800\n",
      "          4       0.16      0.81      0.26       269\n",
      "          5       0.82      0.98      0.89       274\n",
      "          6       0.98      0.80      0.88      1414\n",
      "          7       0.62      0.67      0.65       284\n",
      "          8       0.94      0.70      0.80       846\n",
      "          9       0.82      0.65      0.72       496\n",
      "\n",
      "avg / total       0.76      0.59      0.62      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15624, 93) (15624,)\n",
      "Train score:  0.71424\n",
      "Test score:  0.71202\n",
      "Log loss train:  0.79894\n",
      "Log loss test:  0.81376\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 137    0    2    2    2    3    8   17   22]\n",
      " [  22  927  320  275   20    2   35    4    7]\n",
      " [   3  207  368  176    6    1   35    2    2]\n",
      " [   0   38   33  177    6    7    8    0    0]\n",
      " [   2    3    2    0  267    0    0    0    0]\n",
      " [  53    6    5   24    1 1216   49   26   34]\n",
      " [  20    6   20   14    1    5  212    4    2]\n",
      " [  76    3    5    0    0   12   19  717   14]\n",
      " [  79    4    1    4    0    9    5    9  385]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.35      0.71      0.47       193\n",
      "          2       0.78      0.58      0.66      1612\n",
      "          3       0.49      0.46      0.47       800\n",
      "          4       0.26      0.66      0.38       269\n",
      "          5       0.88      0.97      0.93       274\n",
      "          6       0.97      0.86      0.91      1414\n",
      "          7       0.57      0.75      0.65       284\n",
      "          8       0.92      0.85      0.88       846\n",
      "          9       0.83      0.78      0.80       496\n",
      "\n",
      "avg / total       0.77      0.71      0.73      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_os, y_os = rus.fit_sample(X_train,y_train)\n",
    "print(X_os.shape, y_os.shape)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X=X_os,y=y_os)\n",
    "evaluate_model(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Near miss under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_evaluate(sampling, X_train, y_train):\n",
    "    X_os, y_os = sampling.fit_sample(X_train,y_train)\n",
    "    print(X_os.shape, y_os.shape)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X=X_os,y=y_os)\n",
    "    evaluate_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nm1 = NearMiss(random_state=0, version=1,n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15624, 93) (15624,)\n",
      "Train score:  0.53974\n",
      "Test score:  0.54945\n",
      "Log loss train:  2.37182\n",
      "Log loss test:  2.35544\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 111    6    0    4    1    8    9   17   37]\n",
      " [  23  337  226  739   76    9  186   10    6]\n",
      " [   2   59  161  320   41    2  202   12    1]\n",
      " [   0   16   31  191    4    4   22    0    1]\n",
      " [   0    4    0    4  265    0    0    0    1]\n",
      " [  82    5    0   47    2 1137   97   25   19]\n",
      " [  11   10    7    8    1    6  235    4    2]\n",
      " [  90    5    1    5    0   16   63  651   15]\n",
      " [ 121    9    1   21    0   10    7   15  312]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.25      0.58      0.35       193\n",
      "          2       0.75      0.21      0.33      1612\n",
      "          3       0.38      0.20      0.26       800\n",
      "          4       0.14      0.71      0.24       269\n",
      "          5       0.68      0.97      0.80       274\n",
      "          6       0.95      0.80      0.87      1414\n",
      "          7       0.29      0.83      0.43       284\n",
      "          8       0.89      0.77      0.82       846\n",
      "          9       0.79      0.63      0.70       496\n",
      "\n",
      "avg / total       0.70      0.55      0.56      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_os, y_os = nm1.fit_sample(X_train,y_train)\n",
    "print(X_os.shape, y_os.shape)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X=X_os,y=y_os)\n",
    "evaluate_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nm2 = NearMiss(random_state=42, version=2,n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15624, 93) (15624,)\n",
      "Train score:  0.57298\n",
      "Test score:  0.57143\n",
      "Log loss train:  1.01909\n",
      "Log loss test:  1.03002\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 112    1    2    6    1    4   10   13   44]\n",
      " [  10  300  123 1073   32    5   43    3   23]\n",
      " [   1  115  161  477    3    0   32    3    8]\n",
      " [   0   12    4  238    5    4    6    0    0]\n",
      " [   0    1    2    2  267    0    0    1    1]\n",
      " [  31    3    3   66    4 1193   47   19   48]\n",
      " [  11    3    6   36    1    6  212    5    4]\n",
      " [  53    7    6    4    0   29   23  683   41]\n",
      " [  74    1    3   19    0   11    7   11  370]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.38      0.58      0.46       193\n",
      "          2       0.68      0.19      0.29      1612\n",
      "          3       0.52      0.20      0.29       800\n",
      "          4       0.12      0.88      0.22       269\n",
      "          5       0.85      0.97      0.91       274\n",
      "          6       0.95      0.84      0.89      1414\n",
      "          7       0.56      0.75      0.64       284\n",
      "          8       0.93      0.81      0.86       846\n",
      "          9       0.69      0.75      0.71       496\n",
      "\n",
      "avg / total       0.72      0.57      0.59      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit_evaluate(nm2, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nm3 = NearMiss(random_state=42, version=3,n_neighbors_ver3=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/imblearn/under_sampling/prototype_selection/nearmiss.py:211: UserWarning: The number of the samples to be selected is larger than the number of samples available. The balancing ratio cannot be ensure and all samples will be returned.\n",
      "  warnings.warn('The number of the samples to be selected is larger'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11781, 93) (11781,)\n",
      "Train score:  0.69962\n",
      "Test score:  0.70023\n",
      "Log loss train:  0.88521\n",
      "Log loss test:  0.89183\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  97    7    4    1    2   15    2   26   39]\n",
      " [  10  888  395  268   20    8   15    6    2]\n",
      " [   1  300  373   94    3    1   26    2    0]\n",
      " [   1   55   60  133    5    7    7    0    1]\n",
      " [   0    2    3    0  266    0    0    2    1]\n",
      " [   8   15    4   10   15 1280   35   28   19]\n",
      " [   7   19   30    9    0   15  189   13    2]\n",
      " [  21    8   11    1    2   59   18  716   10]\n",
      " [  46   10    3    4    0   18    1   23  391]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.50      0.51       193\n",
      "          2       0.68      0.55      0.61      1612\n",
      "          3       0.42      0.47      0.44       800\n",
      "          4       0.26      0.49      0.34       269\n",
      "          5       0.85      0.97      0.91       274\n",
      "          6       0.91      0.91      0.91      1414\n",
      "          7       0.65      0.67      0.66       284\n",
      "          8       0.88      0.85      0.86       846\n",
      "          9       0.84      0.79      0.81       496\n",
      "\n",
      "avg / total       0.72      0.70      0.71      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit_evaluate(nm3, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tomek links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enn = EditedNearestNeighbours(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32804, 93) (32804,)\n",
      "Train score:  0.75139\n",
      "Test score:  0.7521\n",
      "Log loss train:  0.81867\n",
      "Log loss test:  0.82391\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 118   16    0    1    1   12    3   21   21]\n",
      " [  10 1454  112    5    9    9    9    3    1]\n",
      " [   3  570  199    2    0    1   21    2    2]\n",
      " [   0  181   35   25    4   18    5    1    0]\n",
      " [   0   14    1    0  259    0    0    0    0]\n",
      " [  26   32    0    2    0 1298   20   20   16]\n",
      " [  31   37   21    0    1   19  160   13    2]\n",
      " [  40   11    1    1    0   22    8  759    4]\n",
      " [  64   17    1    0    0   14    3   15  382]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.40      0.61      0.49       193\n",
      "          2       0.62      0.90      0.74      1612\n",
      "          3       0.54      0.25      0.34       800\n",
      "          4       0.69      0.09      0.16       269\n",
      "          5       0.95      0.95      0.95       274\n",
      "          6       0.93      0.92      0.92      1414\n",
      "          7       0.70      0.56      0.62       284\n",
      "          8       0.91      0.90      0.90       846\n",
      "          9       0.89      0.77      0.83       496\n",
      "\n",
      "avg / total       0.76      0.75      0.73      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit_evaluate(enn, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iht = InstanceHardnessThreshold(random_state=42, estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15624, 93) (15624,)\n",
      "Train score:  0.52932\n",
      "Test score:  0.52666\n",
      "Log loss train:  1.87048\n",
      "Log loss test:  1.91493\n",
      "\n",
      "Confusion Matrix: \n",
      " [[166   1   0   3   0   1  10   3   9]\n",
      " [125 630 269 541  14   2  29   0   2]\n",
      " [ 25 125 319 294   4   0  32   0   1]\n",
      " [  9  17  16 212   4   2   9   0   0]\n",
      " [ 14   3   5   2 249   0   0   0   1]\n",
      " [348  14   7 129   2 766 126   9  13]\n",
      " [ 37   4  12  22   1   0 205   1   2]\n",
      " [336   6  17  13   0   6  27 433   8]\n",
      " [197   5   2   7   0   0   4   2 279]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.13      0.86      0.23       193\n",
      "          2       0.78      0.39      0.52      1612\n",
      "          3       0.49      0.40      0.44       800\n",
      "          4       0.17      0.79      0.28       269\n",
      "          5       0.91      0.91      0.91       274\n",
      "          6       0.99      0.54      0.70      1414\n",
      "          7       0.46      0.72      0.56       284\n",
      "          8       0.97      0.51      0.67       846\n",
      "          9       0.89      0.56      0.69       496\n",
      "\n",
      "avg / total       0.77      0.53      0.58      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit_evaluate(iht, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination of over and under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smote_enn = SMOTEENN(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110862, 93) (110862,)\n",
      "Train score:  0.64387\n",
      "Test score:  0.63849\n",
      "Log loss train:  1.0515\n",
      "Log loss test:  1.07592\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 138    1    2    3    1    2   11   14   21]\n",
      " [  32  444  427  616   21    2   58    3    9]\n",
      " [   3   48  378  305    4    1   58    1    2]\n",
      " [   1    6   22  217    5    6   12    0    0]\n",
      " [   1    0    4    1  268    0    0    0    0]\n",
      " [  72    2    5   25    2 1190   54   21   43]\n",
      " [  18    1    8   22    1    3  225    2    4]\n",
      " [  78    2    5    1    0    9   22  713   16]\n",
      " [  85    1    2    6    0    7    6   11  378]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.32      0.72      0.44       193\n",
      "          2       0.88      0.28      0.42      1612\n",
      "          3       0.44      0.47      0.46       800\n",
      "          4       0.18      0.81      0.30       269\n",
      "          5       0.89      0.98      0.93       274\n",
      "          6       0.98      0.84      0.90      1414\n",
      "          7       0.50      0.79      0.62       284\n",
      "          8       0.93      0.84      0.89       846\n",
      "          9       0.80      0.76      0.78       496\n",
      "\n",
      "avg / total       0.78      0.64      0.65      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit_evaluate(smote_enn, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 3.5643881208397339,\n",
       " 2: 0.42644919212803428,\n",
       " 3: 0.85893639336171268,\n",
       " 4: 2.5548215432608496,\n",
       " 5: 2.5102546765832772,\n",
       " 6: 0.48642227637589636,\n",
       " 7: 2.4218308327897371,\n",
       " 8: 0.81225751874216034,\n",
       " 9: 1.3877052652562856}"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "cw\n",
    "\n",
    "cw_pairs = [(i,cw[i-1]) for i in np.arange(1,10)]\n",
    "cw_dict = dict(cw_pairs)\n",
    "cw_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_weighted = LogisticRegression(class_weight=cw_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0,\n",
       "          class_weight={1: 3.5643881208397339, 2: 0.42644919212803428, 3: 0.85893639336171268, 4: 2.5548215432608496, 5: 2.5102546765832772, 6: 0.48642227637589636, 7: 2.4218308327897371, 8: 0.81225751874216034, 9: 1.3877052652562856},\n",
       "          dual=False, fit_intercept=True, intercept_scaling=1,\n",
       "          max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2',\n",
       "          random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_weighted.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.75419\n",
      "Test score:  0.75323\n",
      "Log loss train:  0.72042\n",
      "Log loss test:  0.73284\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 121    4    0    1    1    5    7   22   32]\n",
      " [  19 1214  242   86   11    4   24    6    6]\n",
      " [   2  381  311   64    2    1   36    2    1]\n",
      " [   0   93   33  120    5    8    9    0    1]\n",
      " [   1    4    2    0  267    0    0    0    0]\n",
      " [  38   13    3    9    2 1260   34   27   28]\n",
      " [  21   15   16   10    1    7  205    7    2]\n",
      " [  45    5    4    0    0   15   14  754    9]\n",
      " [  49    6    0    2    0   13    4   13  409]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.63      0.49       193\n",
      "          2       0.70      0.75      0.73      1612\n",
      "          3       0.51      0.39      0.44       800\n",
      "          4       0.41      0.45      0.43       269\n",
      "          5       0.92      0.97      0.95       274\n",
      "          6       0.96      0.89      0.92      1414\n",
      "          7       0.62      0.72      0.66       284\n",
      "          8       0.91      0.89      0.90       846\n",
      "          9       0.84      0.82      0.83       496\n",
      "\n",
      "avg / total       0.76      0.75      0.75      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(lr_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try one vs all approach\n",
    "\n",
    "Steps to follow:\n",
    "1. Fit model for each class vs all other classes\n",
    "2. Use the balanced classes for the above\n",
    "3. For new data, predict the class with highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55690, 93)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1736,\n",
       "         2: 14510,\n",
       "         3: 7204,\n",
       "         4: 2422,\n",
       "         5: 2465,\n",
       "         6: 12721,\n",
       "         7: 2555,\n",
       "         8: 7618,\n",
       "         9: 4459})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make labels for one vs rest\n",
    "def make_ovr_label(y, one_class):\n",
    "    print(\"old y distribution: \", Counter(y))\n",
    "    y_new = y.copy()\n",
    "    y_new[y_new!=one_class] = 0\n",
    "    y_new[y_new==one_class] = 1\n",
    "    print(\"new y distribution: \", Counter(y_new))\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old y distribution:  Counter({2: 14510, 6: 12721, 8: 7618, 3: 7204, 9: 4459, 7: 2555, 5: 2465, 4: 2422, 1: 1736})\n",
      "new y distribution:  Counter({0: 53954, 1: 1736})\n"
     ]
    }
   ],
   "source": [
    "y_train_1 = make_ovr_label(y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old y distribution:  Counter({2: 1612, 6: 1414, 8: 846, 3: 800, 9: 496, 7: 284, 5: 274, 4: 269, 1: 193})\n",
      "new y distribution:  Counter({0: 5995, 1: 193})\n"
     ]
    }
   ],
   "source": [
    "y_test_1 = make_ovr_label(y_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_1 = LogisticRegression()\n",
    "lr_1.fit(X_train,y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.97184\n",
      "Test score:  0.9722\n",
      "Log loss train:  0.08113\n",
      "Log loss test:  0.08773\n",
      "\n",
      "Confusion Matrix: \n",
      " [[5982   13]\n",
      " [ 159   34]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      5995\n",
      "          1       0.72      0.18      0.28       193\n",
      "\n",
      "avg / total       0.97      0.97      0.96      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_balance(lr_1,y_train_1,y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def plot_roc(fpr,tpr,roc_auc):\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SMOTE ENN sampling for class imbalance\n",
    "def fit_evaluate(sampling, X_train, y_train, X_test, y_test):\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "    X_os, y_os = sampling.fit_sample(X_train,y_train)\n",
    "    print(X_os.shape, y_os.shape)\n",
    "    print(Counter(y_os))\n",
    "    lr = LogisticRegressionCV(cv=5,scoring=\"neg_log_loss\",random_state=42,Cs=[0.1,1,10])\n",
    "    lr.fit(X=X_os,y=y_os)\n",
    "    evaluate_model_balance(lr,y_train,y_test)\n",
    "    fpr, tpr, thresholds  = roc_curve(y_true=y_test,y_score=lr.predict(X_test))\n",
    "    roc_auc = roc_auc_score(y_true=y_test,y_score=lr.predict(X_test))\n",
    "    print(fpr,tpr,thresholds)\n",
    "    plot_roc(fpr,tpr,roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55690, 93) (55690,)\n",
      "(6188, 93) (6188,)\n",
      "(3472, 93) (3472,)\n",
      "Counter({0: 1736, 1: 1736})\n",
      "Train score:  0.8575\n",
      "Test score:  0.85407\n",
      "Log loss train:  0.337\n",
      "Log loss test:  0.33725\n",
      "\n",
      "Confusion Matrix: \n",
      " [[5114  881]\n",
      " [  22  171]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92      5995\n",
      "          1       0.16      0.89      0.27       193\n",
      "\n",
      "avg / total       0.97      0.85      0.90      6188\n",
      "\n",
      "[ 0.         0.1469558  1.       ] [ 0.          0.88601036  1.        ] [2 1 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIqWUUl25UKSUUqrrJ8BesxYyJsjCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11113b668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random under sampling for one class\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "enn = EditedNearestNeighbours(random_state=42)\n",
    "fit_evaluate(rus, X_train, y_train_1, X_test, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103242, 93) (103242,)\n",
      "Train score:  0.85015\n",
      "Test score:  0.84712\n",
      "Log loss train:  0.37417\n",
      "Log loss test:  0.38388\n",
      "\n",
      "Confusion Matrix: \n",
      " [[5073  922]\n",
      " [  24  169]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.91      5995\n",
      "          1       0.15      0.88      0.26       193\n",
      "\n",
      "avg / total       0.97      0.85      0.89      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SMOTE ENN sampling for class imbalance\n",
    "fit_evaluate(smote_enn, X_train, y_train_1, X_test, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RandomUnderSampler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old y distribution:  Counter({2: 14510, 6: 12721, 8: 7618, 3: 7204, 9: 4459, 7: 2555, 5: 2465, 4: 2422, 1: 1736})\n",
      "new y distribution:  Counter({0: 53954, 1: 1736})\n",
      "old y distribution:  Counter({2: 14510, 6: 12721, 8: 7618, 3: 7204, 9: 4459, 7: 2555, 5: 2465, 4: 2422, 1: 1736})\n",
      "new y distribution:  Counter({0: 41180, 1: 14510})\n",
      "old y distribution:  Counter({2: 14510, 6: 12721, 8: 7618, 3: 7204, 9: 4459, 7: 2555, 5: 2465, 4: 2422, 1: 1736})\n",
      "new y distribution:  Counter({0: 48486, 1: 7204})\n",
      "old y distribution:  Counter({2: 14510, 6: 12721, 8: 7618, 3: 7204, 9: 4459, 7: 2555, 5: 2465, 4: 2422, 1: 1736})\n",
      "new y distribution:  Counter({0: 53268, 1: 2422})\n",
      "old y distribution:  Counter({2: 14510, 6: 12721, 8: 7618, 3: 7204, 9: 4459, 7: 2555, 5: 2465, 4: 2422, 1: 1736})\n",
      "new y distribution:  Counter({0: 53225, 1: 2465})\n",
      "old y distribution:  Counter({2: 14510, 6: 12721, 8: 7618, 3: 7204, 9: 4459, 7: 2555, 5: 2465, 4: 2422, 1: 1736})\n",
      "new y distribution:  Counter({0: 42969, 1: 12721})\n",
      "old y distribution:  Counter({2: 14510, 6: 12721, 8: 7618, 3: 7204, 9: 4459, 7: 2555, 5: 2465, 4: 2422, 1: 1736})\n",
      "new y distribution:  Counter({0: 53135, 1: 2555})\n",
      "old y distribution:  Counter({2: 14510, 6: 12721, 8: 7618, 3: 7204, 9: 4459, 7: 2555, 5: 2465, 4: 2422, 1: 1736})\n",
      "new y distribution:  Counter({0: 48072, 1: 7618})\n",
      "old y distribution:  Counter({2: 14510, 6: 12721, 8: 7618, 3: 7204, 9: 4459, 7: 2555, 5: 2465, 4: 2422, 1: 1736})\n",
      "new y distribution:  Counter({0: 51231, 1: 4459})\n",
      "old y distribution:  Counter({2: 1612, 6: 1414, 8: 846, 3: 800, 9: 496, 7: 284, 5: 274, 4: 269, 1: 193})\n",
      "new y distribution:  Counter({0: 5995, 1: 193})\n",
      "old y distribution:  Counter({2: 1612, 6: 1414, 8: 846, 3: 800, 9: 496, 7: 284, 5: 274, 4: 269, 1: 193})\n",
      "new y distribution:  Counter({0: 4576, 1: 1612})\n",
      "old y distribution:  Counter({2: 1612, 6: 1414, 8: 846, 3: 800, 9: 496, 7: 284, 5: 274, 4: 269, 1: 193})\n",
      "new y distribution:  Counter({0: 5388, 1: 800})\n",
      "old y distribution:  Counter({2: 1612, 6: 1414, 8: 846, 3: 800, 9: 496, 7: 284, 5: 274, 4: 269, 1: 193})\n",
      "new y distribution:  Counter({0: 5919, 1: 269})\n",
      "old y distribution:  Counter({2: 1612, 6: 1414, 8: 846, 3: 800, 9: 496, 7: 284, 5: 274, 4: 269, 1: 193})\n",
      "new y distribution:  Counter({0: 5914, 1: 274})\n",
      "old y distribution:  Counter({2: 1612, 6: 1414, 8: 846, 3: 800, 9: 496, 7: 284, 5: 274, 4: 269, 1: 193})\n",
      "new y distribution:  Counter({0: 4774, 1: 1414})\n",
      "old y distribution:  Counter({2: 1612, 6: 1414, 8: 846, 3: 800, 9: 496, 7: 284, 5: 274, 4: 269, 1: 193})\n",
      "new y distribution:  Counter({0: 5904, 1: 284})\n",
      "old y distribution:  Counter({2: 1612, 6: 1414, 8: 846, 3: 800, 9: 496, 7: 284, 5: 274, 4: 269, 1: 193})\n",
      "new y distribution:  Counter({0: 5342, 1: 846})\n",
      "old y distribution:  Counter({2: 1612, 6: 1414, 8: 846, 3: 800, 9: 496, 7: 284, 5: 274, 4: 269, 1: 193})\n",
      "new y distribution:  Counter({0: 5692, 1: 496})\n"
     ]
    }
   ],
   "source": [
    "y_trains = [make_ovr_label(y_train, i) for i in np.arange(1,10)]\n",
    "y_tests = [make_ovr_label(y_test, i) for i in np.arange(1,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrs = [LogisticRegression() for i in np.arange(1,10)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False)]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lrs[i].fit(X_train,y_trains[i]) for i in np.arange(0,9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_probs = [lrs[i].predict_proba(X_test.iloc[0:1,:]).flatten() for i in np.arange(0,9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.80384653,  0.19615347]),\n",
       " array([ 0.90601923,  0.09398077]),\n",
       " array([ 0.7894577,  0.2105423]),\n",
       " array([ 0.99716568,  0.00283432]),\n",
       " array([  9.99999986e-01,   1.43134517e-08]),\n",
       " array([ 0.83294029,  0.16705971]),\n",
       " array([ 0.90321867,  0.09678133]),\n",
       " array([ 0.78114804,  0.21885196]),\n",
       " array([ 0.65925352,  0.34074648])]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "y_pred_probs = []\n",
    "for row in np.arange(0,X_test.shape[0]):\n",
    "    predict_probs = [lrs[i].predict_proba(X_test.iloc[row:row+1,:]).flatten() for i in np.arange(0,9)]\n",
    "    y_preds.append(np.argmax(np.transpose(predict_probs)[1])+1)\n",
    "    y_pred_probs.append(np.transpose(predict_probs)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.96153474e-01,   9.39807717e-02,   2.10542301e-01,\n",
       "         2.83432245e-03,   1.43134517e-08,   1.67059706e-01,\n",
       "         9.67813285e-02,   2.18851960e-01,   3.40746481e-01])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6188,)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss test:  0.671511588758\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  56   27    0    0    0   21    2   41   46]\n",
      " [   0 1438  138    5    8    6   10    5    2]\n",
      " [   0  565  217    3    0    1   10    3    1]\n",
      " [   0  168   29   45    4   19    4    0    0]\n",
      " [   0   15    2    0  257    0    0    0    0]\n",
      " [   3   34    1    3    0 1301   23   29   20]\n",
      " [   2   55   20    1    0   30  159   14    3]\n",
      " [  10   16    2    0    0   27   10  772    9]\n",
      " [   5   26    0    1    0   15    1   19  429]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.29      0.42       193\n",
      "          2       0.61      0.89      0.73      1612\n",
      "          3       0.53      0.27      0.36       800\n",
      "          4       0.78      0.17      0.28       269\n",
      "          5       0.96      0.94      0.95       274\n",
      "          6       0.92      0.92      0.92      1414\n",
      "          7       0.73      0.56      0.63       284\n",
      "          8       0.87      0.91      0.89       846\n",
      "          9       0.84      0.86      0.85       496\n",
      "\n",
      "avg / total       0.76      0.76      0.73      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Log loss test: \",log_loss(y_test, y_pred_probs))\n",
    "print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, y_preds))\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test, y_preds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7553329023917259"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs all with balanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the binary classes\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_oss = []\n",
    "y_oss =[]\n",
    "for i in np.arange(0,9):\n",
    "    X_os, y_os = rus.fit_sample(X_train,y_trains[i])\n",
    "    X_oss.append(X_os)\n",
    "    y_oss.append(y_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrs = [LogisticRegressionCV(cv=5) for i in np.arange(1,10)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0),\n",
       " LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0),\n",
       " LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0),\n",
       " LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0),\n",
       " LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0),\n",
       " LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0),\n",
       " LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0),\n",
       " LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0),\n",
       " LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lrs[i].fit(X_oss[i],y_oss[i]) for i in np.arange(0,9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "y_pred_probs = []\n",
    "for row in np.arange(0,X_test.shape[0]):\n",
    "    predict_probs = [lrs[i].predict_proba(X_test.iloc[row:row+1,:]).flatten() for i in np.arange(0,9)]\n",
    "    y_preds.append(np.argmax(np.transpose(predict_probs)[1])+1)\n",
    "    y_pred_probs.append(np.transpose(predict_probs)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss test:  0.949572140707\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 105    4    0    0    1    5   10   27   41]\n",
      " [  16 1120  247  171   21    2   24    5    6]\n",
      " [   2  330  277  133    4    1   46    3    4]\n",
      " [   0   76   32  140    4   10    7    0    0]\n",
      " [   1    4    3    0  266    0    0    0    0]\n",
      " [  33   12    4   14    1 1259   34   29   28]\n",
      " [  21   14   10   14    2   11  201   10    1]\n",
      " [  38    4    4    1    0   14   15  753   17]\n",
      " [  41    6    0    2    0   12    4   14  417]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.54      0.47       193\n",
      "          2       0.71      0.69      0.70      1612\n",
      "          3       0.48      0.35      0.40       800\n",
      "          4       0.29      0.52      0.38       269\n",
      "          5       0.89      0.97      0.93       274\n",
      "          6       0.96      0.89      0.92      1414\n",
      "          7       0.59      0.71      0.64       284\n",
      "          8       0.90      0.89      0.89       846\n",
      "          9       0.81      0.84      0.83       496\n",
      "\n",
      "avg / total       0.75      0.73      0.74      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Log loss test: \",log_loss(y_test, y_pred_probs))\n",
    "print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, y_preds))\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
