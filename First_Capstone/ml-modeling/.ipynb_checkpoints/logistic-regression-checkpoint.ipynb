{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to follow\n",
    "\n",
    "1. Get train test split\n",
    "1. Fit default model. Also fit using cross validation\n",
    "2. Evaluate the model\n",
    "3. Change parameters and hyperparameters\n",
    "4. Evaluate all models\n",
    "5. Compare all models\n",
    "6. Find out feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imoprt libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit,cross_validate\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import log_loss,classification_report,confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# over sampling for imbalanced classes\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.402093</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>-0.279443</td>\n",
       "      <td>-0.161867</td>\n",
       "      <td>-0.119331</td>\n",
       "      <td>-0.188045</td>\n",
       "      <td>-0.293664</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>-0.243606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246100</td>\n",
       "      <td>-0.420870</td>\n",
       "      <td>-0.249802</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>-0.176699</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.253508</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>-0.279443</td>\n",
       "      <td>-0.161867</td>\n",
       "      <td>-0.119331</td>\n",
       "      <td>-0.188045</td>\n",
       "      <td>0.149647</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>-0.243606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280099</td>\n",
       "      <td>-0.420870</td>\n",
       "      <td>-0.249802</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>-0.176699</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.253508</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>-0.279443</td>\n",
       "      <td>-0.161867</td>\n",
       "      <td>-0.119331</td>\n",
       "      <td>-0.188045</td>\n",
       "      <td>0.149647</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>-0.243606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280099</td>\n",
       "      <td>-0.420870</td>\n",
       "      <td>-0.249802</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>-0.176699</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.402093</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>0.079240</td>\n",
       "      <td>13.508710</td>\n",
       "      <td>4.524667</td>\n",
       "      <td>4.665884</td>\n",
       "      <td>-0.293664</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>0.679472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280099</td>\n",
       "      <td>-0.047949</td>\n",
       "      <td>1.019683</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>-0.176699</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.253508</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>-0.279443</td>\n",
       "      <td>-0.161867</td>\n",
       "      <td>-0.119331</td>\n",
       "      <td>-0.188045</td>\n",
       "      <td>-0.293664</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>-0.243606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246100</td>\n",
       "      <td>-0.420870</td>\n",
       "      <td>-0.249802</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>0.040798</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3          4         5         6  \\\n",
       "0  0.402093 -0.210106 -0.307165 -0.279443  -0.161867 -0.119331 -0.188045   \n",
       "1 -0.253508 -0.210106 -0.307165 -0.279443  -0.161867 -0.119331 -0.188045   \n",
       "2 -0.253508 -0.210106 -0.307165 -0.279443  -0.161867 -0.119331 -0.188045   \n",
       "3  0.402093 -0.210106 -0.307165  0.079240  13.508710  4.524667  4.665884   \n",
       "4 -0.253508 -0.210106 -0.307165 -0.279443  -0.161867 -0.119331 -0.188045   \n",
       "\n",
       "          7         8         9   ...          84        85        86  \\\n",
       "0 -0.293664 -0.291038 -0.243606   ...    0.246100 -0.420870 -0.249802   \n",
       "1  0.149647 -0.291038 -0.243606   ...   -0.280099 -0.420870 -0.249802   \n",
       "2  0.149647 -0.291038 -0.243606   ...   -0.280099 -0.420870 -0.249802   \n",
       "3 -0.293664 -0.291038  0.679472   ...   -0.280099 -0.047949  1.019683   \n",
       "4 -0.293664 -0.291038 -0.243606   ...    0.246100 -0.420870 -0.249802   \n",
       "\n",
       "         87        88        89        90        91        92  target  \n",
       "0 -0.413584 -0.299712 -0.176699 -0.129516 -0.386938 -0.104963       1  \n",
       "1 -0.413584 -0.299712 -0.176699 -0.129516 -0.386938 -0.104963       1  \n",
       "2 -0.413584 -0.299712 -0.176699 -0.129516 -0.386938 -0.104963       1  \n",
       "3 -0.413584 -0.299712 -0.176699 -0.129516 -0.386938 -0.104963       1  \n",
       "4 -0.413584 -0.299712  0.040798 -0.129516 -0.386938 -0.104963       1  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should I use normalized data for all models?\n",
    "# using pca components instead of normal features is a good idea? I don't think so.\n",
    "# for logistic regression it is better to use nomralized data\n",
    "\n",
    "df = pd.read_csv(\"../data/train_norm.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=1, random_state=42, test_size=0.1,\n",
      "            train_size=None)\n"
     ]
    }
   ],
   "source": [
    "# here the classes are imbalanced so we should use stratified split \n",
    "# the folds are made by preserving the percentage of samples for each class\n",
    "# note that the imbalance will still be their when we train the model using this split\n",
    "\n",
    "# since we have big amount of data our test set can be just 1% of all data\n",
    "sss = StratifiedShuffleSplit(n_splits=1,test_size=0.1, random_state=42)\n",
    "print(sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [57972 30244  9427 ..., 60232 28576 27516] TEST: [59081 21681 51999 ...,  1777   269 53901]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"target\",axis=1)\n",
    "y = df.target\n",
    "\n",
    "train_index = []\n",
    "test_index = []\n",
    "\n",
    "for tr, tes in sss.split(X,y):\n",
    "    print(\"TRAIN:\", tr, \"TEST:\", tes)\n",
    "    train_index = tr\n",
    "    test_index = tes\n",
    "\n",
    "X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of data sets\n",
      "X_train:  (55690, 93) y_train:  (55690,)\n",
      "X_train:  (6188, 93) y_test:  (6188,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes of data sets\")\n",
    "print(\"X_train: \", X_train.shape, \"y_train: \", y_train.shape)\n",
    "print(\"X_train: \", X_test.shape,\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(m):\n",
    "    print(\"Train score: \",m.score(X_train,y_train).round(5))\n",
    "    print(\"Test score: \",m.score(X_test,y_test).round(5))\n",
    "    print(\"Log loss train: \",log_loss(y_train, m.predict_proba(X_train)).round(5))\n",
    "    print(\"Log loss test: \",log_loss(y_test, m.predict_proba(X_test)).round(5))\n",
    "    print(\"\\nConfusion Matrix: \\n\", confusion_matrix(y_test, m.predict(X_test),labels=m.classes_))\n",
    "    print(\"\\nClassification Report: \\n\", classification_report(y_test, m.predict(X_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_imp(m):\n",
    "    coef_df = pd.DataFrame(m.coef_)\n",
    "    coef_df = np.absolute(np.round(coef_df,5))\n",
    "\n",
    "    imp_features = [0]*9\n",
    "    for row in np.arange(0,9,1):\n",
    "        # top coefficients for each class\n",
    "        imp_features[row] = sorted(enumerate(coef_df.iloc[row]), \\\n",
    "                                   key=lambda x:x[1],reverse=True)[0:5]\n",
    "\n",
    "    print(\"Most important features: \\n\",np.unique(np.transpose(imp_features)[0])+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.75716\n",
      "Test score:  0.75533\n",
      "Log loss train:  0.66281\n",
      "Log loss test:  0.67151\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  56   27    0    0    0   21    2   41   46]\n",
      " [   0 1438  138    5    8    6   10    5    2]\n",
      " [   0  565  217    3    0    1   10    3    1]\n",
      " [   0  168   29   45    4   19    4    0    0]\n",
      " [   0   15    2    0  257    0    0    0    0]\n",
      " [   3   34    1    3    0 1301   23   29   20]\n",
      " [   2   55   20    1    0   30  159   14    3]\n",
      " [  10   16    2    0    0   27   10  772    9]\n",
      " [   5   26    0    1    0   15    1   19  429]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.29      0.42       193\n",
      "          2       0.61      0.89      0.73      1612\n",
      "          3       0.53      0.27      0.36       800\n",
      "          4       0.78      0.17      0.28       269\n",
      "          5       0.96      0.94      0.95       274\n",
      "          6       0.92      0.92      0.92      1414\n",
      "          7       0.73      0.56      0.63       284\n",
      "          8       0.87      0.91      0.89       846\n",
      "          9       0.84      0.86      0.85       496\n",
      "\n",
      "avg / total       0.76      0.76      0.73      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important features: \n",
      " [  9.  11.  14.  15.  26.  27.  34.  39.  40.  42.  43.  45.  47.  58.  60.\n",
      "  69.  73.  75.  76.  78.  83.  84.  86.  90.]\n"
     ]
    }
   ],
   "source": [
    "feature_imp(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using LogisticRegressionCV\n",
    "lrcv = LogisticRegressionCV(cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcv.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.75725\n",
      "Test score:  0.75727\n",
      "Log loss:  0.6707\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  57   25    0    0    0   21    3   41   46]\n",
      " [   0 1442  137    4    6    6   10    5    2]\n",
      " [   0  561  221    3    0    1   10    3    1]\n",
      " [   0  168   30   44    4   19    4    0    0]\n",
      " [   0   13    2    0  259    0    0    0    0]\n",
      " [   3   35    1    3    1 1302   23   27   19]\n",
      " [   2   53   20    1    1   30  160   14    3]\n",
      " [  11   17    1    0    0   26    9  773    9]\n",
      " [   5   27    0    1    0   15    1   19  428]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.30      0.42       193\n",
      "          2       0.62      0.89      0.73      1612\n",
      "          3       0.54      0.28      0.36       800\n",
      "          4       0.79      0.16      0.27       269\n",
      "          5       0.96      0.95      0.95       274\n",
      "          6       0.92      0.92      0.92      1414\n",
      "          7       0.73      0.56      0.63       284\n",
      "          8       0.88      0.91      0.89       846\n",
      "          9       0.84      0.86      0.85       496\n",
      "\n",
      "avg / total       0.76      0.76      0.73      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(lrcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important features: \n",
      " [  9.  11.  14.  15.  26.  27.  36.  39.  40.  42.  43.  45.  47.  58.  59.\n",
      "  60.  68.  69.  73.  75.  76.  83.  84.  86.  90.]\n"
     ]
    }
   ],
   "source": [
    "feature_imp(lrcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cross validation library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([ 15.76905894,  15.40101194,  14.45040584]),\n",
       " 'score_time': array([ 0.01995587,  0.0199542 ,  0.01813412]),\n",
       " 'test_score': array([-0.68030046, -0.67570131, -0.6716733 ]),\n",
       " 'train_score': array([-0.65810914, -0.66169568, -0.66303738])}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(estimator=lr,cv=3,X=X_train,y=y_train,scoring=('neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive random over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rs = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_os, y_os = rs.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((130590, 93), (130590,))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_os.shape, y_os.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X=X_os,y=y_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.71501\n",
      "Test score:  0.71025\n",
      "Log loss train:  0.78172\n",
      "Log loss test:  0.79707\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 140    2    2    2    2    3    7   14   21]\n",
      " [  23  909  329  291   17    3   32    3    5]\n",
      " [   2  205  371  175    2    1   41    0    3]\n",
      " [   0   38   28  181    5    7   10    0    0]\n",
      " [   1    3    2    0  268    0    0    0    0]\n",
      " [  58    7    4   22    2 1215   46   21   39]\n",
      " [  19    7   16   17    0    3  215    4    3]\n",
      " [  81    3    4    0    0   12   19  714   13]\n",
      " [  79    5    1    5    0   10    3   11  382]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.35      0.73      0.47       193\n",
      "          2       0.77      0.56      0.65      1612\n",
      "          3       0.49      0.46      0.48       800\n",
      "          4       0.26      0.67      0.38       269\n",
      "          5       0.91      0.98      0.94       274\n",
      "          6       0.97      0.86      0.91      1414\n",
      "          7       0.58      0.76      0.65       284\n",
      "          8       0.93      0.84      0.89       846\n",
      "          9       0.82      0.77      0.79       496\n",
      "\n",
      "avg / total       0.77      0.71      0.73      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important features: \n",
      " [ 11.  14.  15.  19.  26.  34.  39.  43.  45.  47.  58.  59.  60.  69.  73.\n",
      "  75.  76.  78.  83.  84.  86.  90.  91.  92.]\n"
     ]
    }
   ],
   "source": [
    "feature_imp(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above naive random over sampling did worse results then our original data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
